{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1be16592-06df-42d3-834e-92001c455abb",
   "metadata": {},
   "source": [
    "# SciAgents\n",
    "## Automating scientific discovery through multi-agent intelligent graph reasoning\n",
    "\n",
    "#### Alireza Ghafarollahi, Markus J. Buehler, MIT, 2024 mbuehler@MIT.EDU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88a310b-5971-4111-9f0e-ac6eef990594",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "!git clone https://github.com/lamm-mit/SciAgentsDiscovery.git\n",
    "%cd SciAgentsDiscovery\n",
    "!pip install -e .\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cbd5ab-8985-443a-abd4-bde904dcd389",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "OpenAI_key=''\n",
    "os.environ['OPENAI_API_KEY']=OpenAI_key\n",
    "\n",
    "SemanticScholar_api_key = ''\n",
    "os.environ['SEMANTIC_SCHOLAR_API_KEY']=SemanticScholar_api_key\n",
    "\n",
    "data_dir_output='./graph_giant_component_LLMdiscovery_example/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d01a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "graph_name = 'large_graph_simple_giant.graphml'\n",
    "hf_hub_download(\n",
    "    repo_id='lamm-mit/bio-graph-1K',\n",
    "    filename=graph_name,\n",
    "    local_dir='./graph_giant_component'\n",
    ")\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "embedding_name = 'embeddings_simple_giant_ge-large-en-v1.5.pkl'\n",
    "hf_hub_download(\n",
    "    repo_id='lamm-mit/bio-graph-1K',\n",
    "    filename=embedding_name,\n",
    "    local_dir='./graph_giant_component'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b37b47a-bbf2-4bcc-802f-4203146a2946",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ScienceDiscovery import *\n",
    "make_dir_if_needed(data_dir_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e29d660-93b2-4ec4-a9e5-0366cf502515",
   "metadata": {},
   "source": [
    "## Research idea generation using the automated multi-agent model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5d67fa-b6c2-4259-a8ee-8db4b1801b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = user.initiate_chat(recipient=manager,\n",
    "message='''Develop a research proposal using random concepts. In the end, rate the novelty and feasibility of the research idea.''',\n",
    "                        clear_history=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02261047-d40f-4bfc-a400-cd2057bc6c20",
   "metadata": {},
   "source": [
    "### Saving the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb50b7c2-6063-410c-b1a2-04c1b74246d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_text = \"\"\n",
    "formatted_text_summary = \"\"\n",
    "for i in range(len(res.chat_history)):\n",
    "    try:\n",
    "        formatted_text += f'''{res.chat_history[i]['tool_calls'][0]['function']['name']}-{res.chat_history[1]['tool_calls'][0]['function']['arguments']}\\n\\n'''\n",
    "    except:\n",
    "        if i==0:\n",
    "            formatted_text += '### ' + f'''{res.chat_history[i]['content']}\\n\\n'''\n",
    "        else:\n",
    "            formatted_text += f'''{res.chat_history[i]['content']}\\n\\n'''\n",
    "            if re.search(\"Summary of the Initial Research Hypothesis\", f'''{res.chat_history[i]['content']}'''):\n",
    "                formatted_text_summary += f'''{res.chat_history[i]['content']}'''\n",
    "\n",
    "text_markdown = Markdown(formatted_text)\n",
    "\n",
    "markdown_to_pdf(formatted_text, 'output_research')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23c9462",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from ScienceDiscovery.utils import ThompsonSamplingBandit, parse_scores, create_path\n",
    "from ScienceDiscovery.graph import G, embedding_tokenizer, embedding_model, node_embeddings\n",
    "from ScienceDiscovery.agents import rate_novelty_feasibility\n",
    "\n",
    "alphas = [i / 10 for i in range(11)]\n",
    "ks = list(range(1, 11))\n",
    "\n",
    "bandit = ThompsonSamplingBandit(alphas, ks)\n",
    "\n",
    "# (alpha, k, novelty, feasibility)\n",
    "history: List[Tuple[float, int, float, float]] = []\n",
    "\n",
    "for _ in range(20):\n",
    "    arm = bandit.select_arm()\n",
    "\n",
    "    _, path_string = create_path(\n",
    "        G,\n",
    "        embedding_tokenizer,\n",
    "        embedding_model,\n",
    "        node_embeddings,\n",
    "        generate_graph_expansion=None,\n",
    "        randomness_factor=arm.alpha,\n",
    "        num_random_waypoints=arm.k,\n",
    "        shortest_path=False,\n",
    "        second_hop=False,\n",
    "        data_dir='./',\n",
    "        save_files=False,\n",
    "        verbatim=True,\n",
    "        keyword_1='silk',\n",
    "        keyword_2='energy-intensive'\n",
    "    )\n",
    "\n",
    "    result = rate_novelty_feasibility(path_string)\n",
    "    novelty, feasibility = parse_scores(result)\n",
    "    reward = 0.5 * (novelty / 10) + 0.5 * (feasibility / 10)\n",
    "\n",
    "    arm.update(reward)\n",
    "    history.append((arm.alpha, arm.k, novelty, feasibility))\n",
    "\n",
    "for i, (a, k, n, f) in enumerate(history):\n",
    "    print(f\"Round {i+1:>2}: α={a:.1f}, k={k:<2d} → Novelty={n:.1f}, Feasibility={f:.1f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SciAgents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
